{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Simulation Framework\n",
    "## Idea is to estimate different levels of idle times at different levels of preemption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Performance Numbers from Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR=os.path.join('checkpointing_baseline', 'async-checkpointing', 'run-86')\n",
    "\n",
    "performance_stats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconfig Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconfig = pd.read_csv(os.path.join(BASE_DIR, 'reconfig.csv'), names=['ws', 'start', 'end', 'elapsed'])\n",
    "reconfig = reconfig.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reconfig_time = reconfig['elapsed'].mean()\n",
    "performance_stats['reconfiguration'] = mean_reconfig_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_times = pd.read_csv(os.path.join(BASE_DIR, 'loop_times_0.csv'), names=['ws', 'step', 'loop start', 'loop end', 'train time', 'start chkpt thread', 'total loop time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_iter_times = {}\n",
    "for ws in loop_times.ws.unique():\n",
    "    filtered_df = loop_times[loop_times['ws'] == ws]\n",
    "    ws_iter_times[ws] = filtered_df['train time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_stats['iter_times'] = ws_iter_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_times = pd.read_csv(os.path.join(BASE_DIR, 'async-checkpoint_0.csv'), names=['elapsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_chkpt_time = chkpt_times['elapsed'].mean()\n",
    "performance_stats['checkpoint'] = mean_chkpt_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_times = pd.read_csv(os.path.join(BASE_DIR, 'load_times_0.csv'), names=['ws', 'step', 'elapsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_load_times = load_times['elapsed'].mean()\n",
    "performance_stats['load checkpoint'] = mean_load_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reconfiguration': 87.87109575271606,\n",
       " 'iter_times': {16: 17.994171783779606,\n",
       "  32: 11.380824764730477,\n",
       "  48: 9.318327348709106,\n",
       "  64: 8.282614257155346},\n",
       " 'checkpoint': 88.99610565625704,\n",
       " 'load checkpoint': 46.83130866289139}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Functions + Importing Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_dt(ts, format=\"%Y-%m-%dT%H:%M:%SZ\"):\n",
    "    return datetime.strptime(ts, format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_node_trace_file = 'full-64-node-trace.csv'\n",
    "real_terminate_trace_file = 'full-64-terminate-trace.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_trace = pd.read_csv(real_node_trace_file)\n",
    "node_trace['dt'] = node_trace['timestamp'].apply(lambda x : ts_to_dt(x))\n",
    "terminate_trace = pd.read_csv(real_terminate_trace_file)\n",
    "terminate_trace['dt'] = terminate_trace['timestamp'].apply(lambda x: ts_to_dt(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Mean Time To Preemption (MTTP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTTP 221.875\n",
      "TTP Std: 171.06669982633582\n"
     ]
    }
   ],
   "source": [
    "ranges = {'ranges': []}\n",
    "for ind in range(len(node_trace) - 1):\n",
    "    row = node_trace.iloc[ind]\n",
    "    next_row = node_trace.iloc[ind + 1]\n",
    "\n",
    "    ranges['ranges'].append((next_row['dt'] - row['dt']).total_seconds())\n",
    "\n",
    "ranges_df = pd.DataFrame(ranges)\n",
    "print(\"MTTP\", ranges_df['ranges'].mean())\n",
    "print(\"TTP Std:\", np.sqrt(ranges_df['ranges'].var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slight Aside: Generate a \"Node Additions\" Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "additions = {\n",
    "    'timestamp': [],\n",
    "    'dt': [],\n",
    "    'count': []\n",
    "}\n",
    "\n",
    "for ind in range(len(node_trace)-1):\n",
    "    row = node_trace.iloc[ind]\n",
    "    next_row = node_trace.iloc[ind+1]\n",
    "\n",
    "    if next_row['count'] > row['count']:\n",
    "        additions['timestamp'].append(row['timestamp'])\n",
    "        additions['dt'].append(ts_to_dt(row['timestamp']))\n",
    "        additions['count'].append(next_row['count'] - row['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "additions_trace = pd.DataFrame(additions)\n",
    "additions_trace.to_csv('full-64-additions-trace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating actual numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preemptions = terminate_trace['number'].sum()\n",
    "total_additions = additions_trace['count'].sum()\n",
    "trace_start = node_trace.iloc[0]['dt']\n",
    "trace_end = node_trace.iloc[len(node_trace)-1]['dt']\n",
    "total_time_td = trace_end - trace_start\n",
    "total_minutes = total_time_td.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39436619718309857\n",
      "0.5295774647887324\n"
     ]
    }
   ],
   "source": [
    "preemptions_per_minute = float(total_preemptions) / float(total_minutes)\n",
    "additions_per_minute = float(total_additions) / float(total_minutes)\n",
    "\n",
    "print(preemptions_per_minute)\n",
    "print(additions_per_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16338028169014085\n",
      "0.14366197183098592\n"
     ]
    }
   ],
   "source": [
    "minutes_preemptions_occurred = len(terminate_trace)\n",
    "minutes_additions_occurred = len(additions_trace)\n",
    "chance_preempt_this_minute = float(minutes_preemptions_occurred) / total_minutes\n",
    "chance_add_this_minute = float(minutes_additions_occurred) / total_minutes\n",
    "\n",
    "print(chance_preempt_this_minute)\n",
    "print(chance_add_this_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058823529411764705\n",
      "0.9411764705882353\n",
      "2.5416666666666665\n",
      "1.9456261184790364\n"
     ]
    }
   ],
   "source": [
    "big_adds = additions_trace[additions_trace['count'] > 10]\n",
    "regular_adds = additions_trace[additions_trace['count'] <= 10]\n",
    "\n",
    "num_big_additions = len(big_adds)\n",
    "num_regular_additions = len(regular_adds)\n",
    "\n",
    "probability_big_add = float(num_big_additions) / float(len(additions_trace))\n",
    "probability_reg_add = float(num_regular_additions) / float(len(additions_trace))\n",
    "\n",
    "assert probability_big_add + probability_reg_add == 1\n",
    "print(probability_big_add)\n",
    "print(probability_reg_add)\n",
    "\n",
    "regular_add_mean = regular_adds['count'].mean()\n",
    "regular_add_std = np.sqrt(regular_adds['count'].var())\n",
    "print(regular_add_mean)\n",
    "print(regular_add_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.413793103448276\n",
      "2.086165648825032\n"
     ]
    }
   ],
   "source": [
    "preempt_count_mean = terminate_trace['number'].mean()\n",
    "preempt_count_std = np.sqrt(terminate_trace['number'].var())\n",
    "\n",
    "print(preempt_count_mean)\n",
    "print(preempt_count_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempted recreation of a preemption trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_preemption_trace = {\n",
    "    'dt': [],\n",
    "    'preemptions': []\n",
    "}\n",
    "\n",
    "generated_addition_trace = {\n",
    "    'dt': [],\n",
    "    'additions': []\n",
    "}\n",
    "\n",
    "curr_dt = datetime(2021, 9, 14, 17, 00)\n",
    "\n",
    "current_instances = 32\n",
    "inst_min = 0\n",
    "inst_max = 64\n",
    "for _ in range(int(total_minutes)):\n",
    "    #print(f'Processing time {curr_dt.(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    preempt_now = np.random.rand()\n",
    "    add_now = np.random.rand()\n",
    "    if preempt_now < chance_preempt_this_minute:\n",
    "        num_to_preempt = np.random.normal(preempt_count_mean, preempt_count_std, 1)[0]\n",
    "        num_to_preempt = np.abs(np.round(num_to_preempt))\n",
    "        if num_to_preempt == 0:\n",
    "            num_to_preempt = 1\n",
    "        #probs = np.random.rand(current_instances)\n",
    "        #keep = probs > chance_preempt_this_minute\n",
    "        generated_preemption_trace['dt'].append(curr_dt)\n",
    "        generated_preemption_trace['preemptions'].append(num_to_preempt)\n",
    "\n",
    "    if add_now < chance_add_this_minute:\n",
    "        big_or_regular = np.random.random()\n",
    "        num_to_add = None\n",
    "        if big_or_regular < probability_big_add:\n",
    "            num_to_add = np.random.randint(11, 32)\n",
    "        else:\n",
    "            num_to_add = np.random.normal(regular_add_mean, regular_add_std, 1)[0]\n",
    "            num_to_add = np.abs(np.round(num_to_add))\n",
    "            if num_to_add == 0:\n",
    "                num_to_add = 1\n",
    "\n",
    "        assert num_to_add != None\n",
    "        generated_addition_trace['dt'].append(curr_dt)\n",
    "        generated_addition_trace['additions'].append(num_to_add)\n",
    "\n",
    "    curr_dt += timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pre_df = pd.DataFrame(generated_preemption_trace)\n",
    "gen_add_df = pd.DataFrame(generated_addition_trace)\n",
    "\n",
    "gen_pre_df.to_csv('generated-preemptions-trace.csv')\n",
    "gen_add_df.to_csv('generated-additions-trace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the actual simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reconfiguration': 88.0,\n",
       " 'iter_times': {16: 18.0, 32: 11.0, 48: 9.0, 64: 8.0},\n",
       " 'checkpoint': 89.0,\n",
       " 'load checkpoint': 47.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_values(d):\n",
    "    new_dict = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            new_dict[k] = round_values(v)\n",
    "        else:\n",
    "            new_dict[k] = np.round(v)\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "performance_stats = round_values(performance_stats)\n",
    "performance_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_next_dir():\n",
    "    base_dir = 'simulation_results'\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    existing_trials_so_far = glob.glob(os.path.join(base_dir, 'run-*'))\n",
    "    existing_trials_so_far = [int(r[r.rfind('-')+1:]) for r in existing_trials_so_far]\n",
    "    next_run = 0 if len(existing_trials_so_far) == 0 else max(existing_trials_so_far) + 1\n",
    "\n",
    "    return os.path.join(base_dir, f'run-{next_run}')\n",
    "\n",
    "def run_simulation(preemption_chance_per_minute, preemption_distribution, addition_chance_per_minute, addition_distribution):\n",
    "    start = datetime(2021, 9, 14, 17, 00)\n",
    "    end = start + timedelta(minutes=total_minutes)\n",
    "\n",
    "    active_instances = set()\n",
    "    standy_instances = set()\n",
    "    prepping_instances = set()\n",
    "    all_instances = set()\n",
    "\n",
    "    prepping_timers = {}\n",
    "    event_timers = {}\n",
    "    current_state = 'training'\n",
    "    event_id = 0\n",
    "\n",
    "    preemption_chance = preemption_chance_per_minute / 12\n",
    "    addition_chance = addition_chance_per_minute / 12\n",
    "\n",
    "    current_instances = 32\n",
    "    pipeline_depth = 16\n",
    "    id = 0\n",
    "    for _ in range(current_instances):\n",
    "        all_instances.add(id)\n",
    "        active_instances.add(id)\n",
    "        id += 1\n",
    "\n",
    "    step = 0\n",
    "    trace = {\n",
    "        'ws': [current_instances],\n",
    "        'dt': [start],\n",
    "        'event': ['step'],\n",
    "        'event-id': [0]\n",
    "    }\n",
    "\n",
    "    reconfig_cnt = 0\n",
    "    reconfig_end_time = None\n",
    "    last_saved_iteration = 0\n",
    "    checkpoint_running = False\n",
    "    checkpoint_start = None\n",
    "    checkpoint_step = 0\n",
    "\n",
    "    inst_min = 0\n",
    "    inst_max = 64\n",
    "    curr_time = start\n",
    "    exp_dir = get_next_dir()\n",
    "    os.makedirs(exp_dir)\n",
    "    f = open(os.path.join(exp_dir, 'simulation-output.txt'), 'w')\n",
    "    while curr_time < end:\n",
    "        f.write(f'{curr_time.strftime(\"%Y-%m-%d %H:%M:%S\")} Cluster Config this step:\\n')\n",
    "        f.write(f'######## {len(active_instances)} active instances: {active_instances}\\n')\n",
    "        f.write(f'######## {len(standy_instances)} standby instances: {standy_instances}\\n')\n",
    "        f.write(f'######## {len(prepping_instances)} prepping instances: {prepping_instances}\\n')\n",
    "        f.write(f'######## {len(all_instances)} total instances: {all_instances}\\n')\n",
    "        f.write('========================================================================\\n')\n",
    "\n",
    "        num_to_add = 0\n",
    "        add_this_round = np.random.random() < addition_chance\n",
    "        if add_this_round:\n",
    "            big_or_regular = np.random.random()\n",
    "            if big_or_regular < 0.05:\n",
    "                num_to_add = np.random.randint(11, 32)\n",
    "                if len(all_instances) + num_to_add >= inst_max:\n",
    "                    num_to_add = inst_max - len(all_instances)\n",
    "            else:\n",
    "                num_to_add = np.random.normal(addition_distribution['mean'], addition_distribution['std'])\n",
    "                num_to_add = np.abs(np.round(num_to_add))\n",
    "                if num_to_add == 0:\n",
    "                    num_to_add = 1\n",
    "                elif len(all_instances) + num_to_add >= inst_max:\n",
    "                    num_to_add = inst_max - len(all_instances)\n",
    "\n",
    "        num_to_preempt = 0\n",
    "        preempt_this_round = np.random.random() < preemption_chance\n",
    "        if preempt_this_round and not len(all_instances) <= inst_min:\n",
    "            num_to_preempt = np.random.normal(preemption_distribution['mean'], preemption_distribution['std'])\n",
    "            num_to_preempt = np.abs(np.round(num_to_preempt))\n",
    "            if num_to_preempt == 0:\n",
    "                num_to_preempt = 1\n",
    "\n",
    "        preempted_instances = random.sample(all_instances, int(num_to_preempt))\n",
    "        if len(preempted_instances) > 0:\n",
    "            f.write(f'Preempting {len(preempted_instances)} with ids {preempted_instances}\\n')\n",
    "        lost_active = False\n",
    "        for inst_id in preempted_instances:\n",
    "            if inst_id in active_instances:\n",
    "                lost_active = True\n",
    "                active_instances.remove(inst_id)\n",
    "            elif inst_id in standy_instances:\n",
    "                standy_instances.remove(inst_id)\n",
    "            elif inst_id in prepping_instances:\n",
    "                prepping_instances.remove(inst_id)\n",
    "                del prepping_timers[inst_id]\n",
    "            else:\n",
    "                print(f'What the F?')\n",
    "\n",
    "            all_instances.remove(inst_id)\n",
    "\n",
    "        done_prepping = []\n",
    "        for inst_id in prepping_instances:\n",
    "            time_spent_prepping = curr_time - prepping_timers[inst_id]\n",
    "            if time_spent_prepping.total_seconds() >= 180:\n",
    "                done_prepping.append(inst_id)\n",
    "\n",
    "        if len(done_prepping) > 0:\n",
    "            f.write(f'Moving {len(done_prepping)} instances to standby with ids {done_prepping}\\n')\n",
    "        for inst_id in done_prepping:\n",
    "            standy_instances.add(inst_id)\n",
    "            prepping_instances.remove(inst_id)\n",
    "            del prepping_timers[inst_id]\n",
    "\n",
    "        if num_to_add > 0:\n",
    "            f.write(f'Adding {num_to_add} new instances with sart id {id}\\n')\n",
    "        for _ in range(int(num_to_add)):\n",
    "            all_instances.add(id)\n",
    "            prepping_instances.add(id)\n",
    "            prepping_timers[id] = curr_time\n",
    "            id += 1\n",
    "\n",
    "        new_pipeline_avail = len(standy_instances) >= pipeline_depth\n",
    "\n",
    "        last_event = {\n",
    "            'ws': trace['ws'][-1],\n",
    "            'dt': trace['dt'][-1],\n",
    "            'event': trace['event'][-1],\n",
    "            'event-id': trace['event-id'][-1]\n",
    "        }\n",
    "        if checkpoint_running:\n",
    "            checkpoint_end_time = checkpoint_start + timedelta(seconds=performance_stats['checkpoint'])\n",
    "            if curr_time > checkpoint_end_time:\n",
    "                f.write(f'Finished checkpoint {checkpoint_step}\\n')\n",
    "                last_saved_iteration = checkpoint_step\n",
    "                checkpoint_running = False\n",
    "\n",
    "        if last_event['event'] == 'step':\n",
    "            iter_end_time = last_event['dt'] + timedelta(seconds=performance_stats['iter_times'][last_event['ws']])\n",
    "            if curr_time > iter_end_time:\n",
    "                if not checkpoint_running:\n",
    "                    checkpoint_start = iter_end_time\n",
    "                    checkpoint_step = step\n",
    "                    checkpoint_running = True\n",
    "\n",
    "                step += 1\n",
    "                trace['ws'].append(last_event['ws'])\n",
    "                trace['dt'].append(iter_end_time)\n",
    "                trace['event'].append('step')\n",
    "                trace['event-id'].append(step)\n",
    "\n",
    "        elif last_event['event'] == 'reconfig':\n",
    "            if lost_active or new_pipeline_avail:\n",
    "                reconfig_end_time += timedelta(seconds=performance_stats['reconfiguration'])\n",
    "            if curr_time > reconfig_end_time:\n",
    "                step = last_saved_iteration + 1\n",
    "                trace['ws'].append(len(active_instances))\n",
    "                trace['dt'].append(reconfig_end_time)\n",
    "                trace['event'].append('step')\n",
    "                trace['event-id'].append(step)\n",
    "                reconfig_end_time = None\n",
    "        else:\n",
    "            print('huh?')\n",
    "\n",
    "        if lost_active or new_pipeline_avail:\n",
    "            trace['ws'].append(len(active_instances))\n",
    "            trace['dt'].append(curr_time)\n",
    "            trace['event'].append('reconfig')\n",
    "            trace['event-id'].append(reconfig_cnt)\n",
    "            reconfig_cnt += 1\n",
    "            if reconfig_end_time == None:\n",
    "                reconfig_end_time = curr_time + timedelta(seconds=performance_stats['reconfiguration'])\n",
    "\n",
    "            checkpoint_running = False\n",
    "\n",
    "            if lost_active and not new_pipeline_avail:\n",
    "                f.write('Lost active instance but no new pipeline avail: ')\n",
    "                diff = len(active_instances) % pipeline_depth\n",
    "                if len(standy_instances) > pipeline_depth - diff:\n",
    "                    f.write('case 1a\\n')\n",
    "                    n_to_move = pipeline_depth - diff\n",
    "                    to_move = random.sample(standy_instances, n_to_move)\n",
    "                    for k in to_move:\n",
    "                        active_instances.add(k)\n",
    "                        standy_instances.remove(k)\n",
    "                else:\n",
    "                    f.write('case 1b\\n')\n",
    "                    to_move = random.sample(active_instances, diff)\n",
    "                    for k in to_move:\n",
    "                        standy_instances.add(k)\n",
    "                        active_instances.remove(k)\n",
    "\n",
    "            elif not lost_active and new_pipeline_avail:\n",
    "                f.write('No instance lost but new pipeline is availalbe\\n')\n",
    "                f.write(f'LEN STDBY: {len(standy_instances)}, pipe depth: {pipeline_depth}, ')\n",
    "                n_to_move = (len(standy_instances) // pipeline_depth) * pipeline_depth\n",
    "                f.write(f'N_TO_MOVE: {n_to_move}\\n')\n",
    "                to_move = random.sample(standy_instances, n_to_move)\n",
    "                for k in to_move:\n",
    "                    active_instances.add(k)\n",
    "                    standy_instances.remove(k)\n",
    "\n",
    "            else:\n",
    "                f.write('Both lost an instance AND got a new pipeline\\n')\n",
    "                diff = len(active_instances) % pipeline_depth\n",
    "                n_to_move = ((len(standy_instances) // pipeline_depth) * pipeline_depth) - diff\n",
    "                to_move = random.sample(standy_instances, n_to_move)\n",
    "                for k in to_move:\n",
    "                    active_instances.add(k)\n",
    "                    standy_instances.remove(k)\n",
    "\n",
    "                while len(standy_instances) >= pipeline_depth:\n",
    "                    move_pipeline = random.sample(standy_instances, pipeline_depth)\n",
    "                    for k in move_pipeline:\n",
    "                        active_instances.add(k)\n",
    "                        standy_instances.remove(k)\n",
    "\n",
    "        curr_time += timedelta(seconds=5)\n",
    "        f.write('========================================================================\\n')\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "    print('done')\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66923/3480826572.py:91: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  preempted_instances = random.sample(all_instances, int(num_to_preempt))\n",
      "/tmp/ipykernel_66923/3480826572.py:195: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  to_move = random.sample(active_instances, diff)\n",
      "/tmp/ipykernel_66923/3480826572.py:205: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  to_move = random.sample(standy_instances, n_to_move)\n",
      "/tmp/ipykernel_66923/3480826572.py:189: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  to_move = random.sample(standy_instances, n_to_move)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66923/91611870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_66923/3480826572.py\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(preemption_chance_per_minute, preemption_distribution, addition_chance_per_minute, addition_distribution)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_event\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0miter_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_event\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperformance_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iter_times'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_event\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ws'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurr_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0miter_end_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_running\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "trace = run_simulation(0.5, {'mean': 0, 'std': 1}, 0.5, {'mean': 0, 'std': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ws</th>\n",
       "      <th>dt</th>\n",
       "      <th>event</th>\n",
       "      <th>event-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2021-09-14 17:00:00</td>\n",
       "      <td>step</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>2021-09-14 17:00:11</td>\n",
       "      <td>step</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2021-09-14 17:00:22</td>\n",
       "      <td>step</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>2021-09-14 17:00:33</td>\n",
       "      <td>step</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>2021-09-14 17:00:44</td>\n",
       "      <td>step</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>191</td>\n",
       "      <td>2021-09-14 22:41:55</td>\n",
       "      <td>reconfig</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>191</td>\n",
       "      <td>2021-09-14 22:49:25</td>\n",
       "      <td>reconfig</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>191</td>\n",
       "      <td>2021-09-14 22:50:55</td>\n",
       "      <td>reconfig</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>190</td>\n",
       "      <td>2021-09-14 22:51:20</td>\n",
       "      <td>reconfig</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>191</td>\n",
       "      <td>2021-09-14 22:52:35</td>\n",
       "      <td>reconfig</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ws                  dt     event  event-id\n",
       "0     32 2021-09-14 17:00:00      step         0\n",
       "1     32 2021-09-14 17:00:11      step         1\n",
       "2     32 2021-09-14 17:00:22      step         2\n",
       "3     32 2021-09-14 17:00:33      step         3\n",
       "4     32 2021-09-14 17:00:44      step         4\n",
       "..   ...                 ...       ...       ...\n",
       "700  191 2021-09-14 22:41:55  reconfig       659\n",
       "701  191 2021-09-14 22:49:25  reconfig       660\n",
       "702  191 2021-09-14 22:50:55  reconfig       661\n",
       "703  190 2021-09-14 22:51:20  reconfig       662\n",
       "704  191 2021-09-14 22:52:35  reconfig       663\n",
       "\n",
       "[705 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_df = pd.DataFrame(trace)\n",
    "trace_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c929047c6c8b6f08da409b06353a3d0df08ff229134b1a034b225da320b6d75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
